{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy\n",
        "from io import StringIO "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_named_entities(text, nlp):\n",
        "    max_length = 1000000  #Maximum allowed length in characters\n",
        "    chunks = (text[i:i + max_length] for i in range(0, len(text), max_length))\n",
        "    named_entities = set()\n",
        "\n",
        "    for chunk in chunks:\n",
        "        doc = nlp(chunk)\n",
        "        named_entities.update((entity.text, entity.label_) for entity in doc.ents)\n",
        "\n",
        "    return named_entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "nlp_ja = spacy.load(\"ja_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#website data\n",
        "file_path = \"corpus_of_Honda.txt\"\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    scraped_data = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "is_english = any(ord(char) < 128 for char in scraped_data)\n",
        "\n",
        "if is_english:\n",
        "    entities_combined = extract_named_entities(scraped_data, nlp_en)\n",
        "else:\n",
        "    entities_combined = extract_named_entities(scraped_data, nlp_ja)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "buffer = StringIO()\n",
        "label_entities_dict = {}\n",
        "for entity, label in entities_combined:\n",
        "    if label not in label_entities_dict:\n",
        "        label_entities_dict[label] = set()\n",
        "    label_entities_dict[label].add(entity)\n",
        "\n",
        "for label, entities_set in label_entities_dict.items():\n",
        "    entities_str = \", \".join(entities_set)\n",
        "    buffer.write(f\"Label: {label}, Entities: {entities_str}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = buffer.getvalue()\n",
        "data_cleaned = data.replace(\"\\n\", \" \")\n",
        "data_cleaned = data_cleaned.replace(\"Label:\", \"\\nLabel:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_file_path = \"entities_are_here.txt\"\n",
        "with open(output_file_path, \"w\", encoding='utf-8') as output_file:\n",
        "    output_file.write(data_cleaned)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
